{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import copy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF():\n",
    "    # initialize paprameters\n",
    "    def __init__(self, m, n, lambda_u=1e-2, lambda_v=1e-2, latent_size=10,\n",
    "                 lr=0.01, num_iter=2000, stopping_deriv=None, seed=None):\n",
    "        self.lambda_u = lambda_u\n",
    "        self.lambda_v = lambda_v\n",
    "        self.random_state = RandomState(seed)\n",
    "        self.latent_size=latent_size\n",
    "        self.lr = lr\n",
    "        self.iterations = num_iter\n",
    "        self.stopping_deriv = stopping_deriv\n",
    "        self.R = np.zeros([n,m])\n",
    "        self.I = None\n",
    "        self.U = None\n",
    "        self.V = None\n",
    "        \n",
    "\n",
    "    def loss(self):\n",
    "        # loss function\n",
    "        loss = 0.5*(np.sum(self.I*(self.R-np.dot(self.U.T, self.V))**2) + self.lambda_u*np.sum(np.square(self.U)) + self.lambda_v*np.sum(np.square(self.V)))\n",
    "        return loss\n",
    "    \n",
    "    def predict(self, data):\n",
    "        index = np.array([[int(element[0]-1), int(element[1]-1)] for element in data], dtype=int)\n",
    "        u_features = self.U.take(index.take(0, axis=1), axis=1)\n",
    "        v_features = self.V.take(index.take(1, axis=1), axis=1)\n",
    "        preds = np.sum(u_features*v_features, 0)\n",
    "        return preds\n",
    "\n",
    "    def fit(self, train_data, validation_data = None):\n",
    "        for element in train_data:\n",
    "            self.R[int(element[0]-1), int(element[1]-1)] = float(element[2])\n",
    "        \n",
    "        self.I = copy.deepcopy(self.R)\n",
    "        self.I[self.I != 0] = 1\n",
    "\n",
    "        self.U = 0.1*self.random_state.rand(self.latent_size, np.size(self.R, 0))\n",
    "        self.V = 0.1*self.random_state.rand(self.latent_size, np.size(self.R, 1))\n",
    "\n",
    "        \n",
    "        last_validation_rmse = None\n",
    "        stop_u = False\n",
    "        stop_v = False\n",
    "\n",
    "        for it in range(self.iterations):\n",
    "            # derivate of U\n",
    "            grads_u = np.dot(self.I*(self.R-np.dot(self.U.T, self.V)), -self.V.T).T + self.lambda_u*self.U\n",
    "\n",
    "            # derivate of V\n",
    "            grads_v = np.dot((self.I*(self.R-np.dot(self.U.T, self.V))).T, -self.U.T).T + self.lambda_v*self.V\n",
    "\n",
    "            # update the parameters\n",
    "            if self.stopping_deriv is None:\n",
    "                self.U = self.U - self.lr * grads_u\n",
    "                self.V = self.V - self.lr * grads_v\n",
    "            else:\n",
    "                if np.all(abs(grads_u) > self.stopping_deriv):\n",
    "                    self.U = self.U - self.lr * grads_u\n",
    "                else:\n",
    "                    stop_u = True\n",
    "\n",
    "                if np.all(abs(grads_v) > self.stopping_deriv):\n",
    "                    self.V = self.V - self.lr * grads_v\n",
    "                else:\n",
    "                    stop_v = True\n",
    "\n",
    "                if stop_u and stop_v:\n",
    "                    print('early stopping:{: d}'.format(it))\n",
    "                    break\n",
    "\n",
    "            # training loss\n",
    "            train_loss = self.loss()\n",
    "            \n",
    "            if validation_data is None:\n",
    "                if (it%100 == 0):\n",
    "                    print('traning iteration:{: d}, loss:{: f}'.format(it, train_loss))\n",
    "            else:\n",
    "                validation_preds = self.predict(validation_data)\n",
    "                validation_rmse = sqrt(mean_squared_error(validation_data[:,2], validation_preds))\n",
    "                if (it%100 == 0):\n",
    "                    print('traning iteration:{: d}, loss:{: f}, validation_rmse:{: f}'.format(it, train_loss, validation_rmse))\n",
    "\n",
    "                if last_validation_rmse and (last_validation_rmse - validation_rmse) <= 0:\n",
    "                    print('convergence at iterations:{: d}'.format(it))\n",
    "                    break\n",
    "                else:\n",
    "                    last_validation_rmse = validation_rmse\n",
    "        train_preds = self.predict(train_data)\n",
    "        train_rmse = sqrt(mean_squared_error(train_data[:,2], train_preds))\n",
    "        \n",
    "        if validation_data is None:\n",
    "            return self.U, self.V, train_rmse\n",
    "        else:\n",
    "            return self.U, self.V, train_rmse, last_validation_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
